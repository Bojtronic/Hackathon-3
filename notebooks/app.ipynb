{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a0f84",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "# üèãÔ∏è‚Äç‚ôÇÔ∏è AI Sports Coach - Colab Test Notebook (Extended)\n",
    "# ==============================================================\n",
    "# This notebook tests your posture detection system using:\n",
    "#  - Webcam frames or static images\n",
    "#  - Uploaded videos (.mp4)\n",
    "#  - Real-time posture risk scoring and feedback overlays\n",
    "# ==============================================================\n",
    "\n",
    "# --- STEP 1: Install dependencies ---\n",
    "!pip install mediapipe opencv-python-headless numpy tqdm\n",
    "\n",
    "# --- STEP 2: Import modules ---\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tqdm import tqdm\n",
    "from google.colab import files\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "\n",
    "# --- STEP 3: Recreate core logic for standalone testing ---\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Calculate angle between 3 points (in degrees).\"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    cos = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    return np.degrees(np.arccos(np.clip(cos, -1.0, 1.0)))\n",
    "\n",
    "\n",
    "def detect_pose_angles(frame, pose):\n",
    "    \"\"\"Run pose estimation on one frame.\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    results = pose.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    if not results.pose_landmarks:\n",
    "        return frame, None\n",
    "\n",
    "    lm = results.pose_landmarks.landmark\n",
    "    left_shoulder = (lm[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w,\n",
    "                     lm[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h)\n",
    "    right_shoulder = (lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w,\n",
    "                      lm[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h)\n",
    "    left_ear = (lm[mp_pose.PoseLandmark.LEFT_EAR].x * w,\n",
    "                lm[mp_pose.PoseLandmark.LEFT_EAR].y * h)\n",
    "\n",
    "    shoulder_angle = calculate_angle(left_shoulder, right_shoulder, (right_shoulder[0], 0))\n",
    "    neck_angle = calculate_angle(left_ear, left_shoulder, (left_shoulder[0], 0))\n",
    "\n",
    "    angles = {\"shoulder_angle\": shoulder_angle, \"neck_angle\": neck_angle}\n",
    "\n",
    "    annotated = frame.copy()\n",
    "    mp_drawing.draw_landmarks(annotated, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    return annotated, angles\n",
    "\n",
    "\n",
    "def assess_posture_risk(angles):\n",
    "    \"\"\"Simple heuristic risk estimation.\"\"\"\n",
    "    shoulder_angle = angles.get(\"shoulder_angle\", 0)\n",
    "    neck_angle = angles.get(\"neck_angle\", 0)\n",
    "\n",
    "    score = 100\n",
    "    feedback = []\n",
    "\n",
    "    if shoulder_angle < 160:\n",
    "        score -= (160 - shoulder_angle) * 0.5\n",
    "        feedback.append(\"‚ö†Ô∏è Shoulders tilted forward ‚Äî possible slouching.\")\n",
    "    if neck_angle < 150:\n",
    "        score -= (150 - neck_angle) * 0.7\n",
    "        feedback.append(\"‚ö†Ô∏è Neck bent ‚Äî possible strain risk.\")\n",
    "\n",
    "    score = np.clip(score, 0, 100)\n",
    "    risk = \"Low\" if score > 85 else \"Medium\" if score > 60 else \"High\"\n",
    "\n",
    "    return {\"score\": float(score), \"risk_level\": risk, \"feedback\": feedback or [\"‚úÖ Good posture.\"]}\n",
    "\n",
    "\n",
    "def draw_feedback(frame, angles, risk_info):\n",
    "    \"\"\"Overlay results on video frame.\"\"\"\n",
    "    color = (0, 255, 0) if risk_info[\"risk_level\"] == \"Low\" else \\\n",
    "            (0, 255, 255) if risk_info[\"risk_level\"] == \"Medium\" else (0, 0, 255)\n",
    "\n",
    "    cv2.putText(frame, f\"Risk: {risk_info['risk_level']}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.putText(frame, f\"Score: {risk_info['score']:.1f}\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "    y = 100\n",
    "    for line in risk_info[\"feedback\"]:\n",
    "        cv2.putText(frame, line, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
    "        y += 25\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b729af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Upload video file\n",
    "print(\"üì§ Upload your .mp4 video for analysis:\")\n",
    "uploaded = files.upload()\n",
    "filename = list(uploaded.keys())[0]\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(filename)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter(\"output.mp4\", cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"üéû Processing {frame_count} frames...\")\n",
    "\n",
    "for _ in tqdm(range(frame_count)):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    annotated, angles = detect_pose_angles(frame, pose)\n",
    "    if angles:\n",
    "        risk = assess_posture_risk(angles)\n",
    "        annotated = draw_feedback(annotated, angles, risk)\n",
    "\n",
    "    out.write(annotated)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(\"‚úÖ Processing complete! Output saved as 'output.mp4'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b3185",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display video inline in Colab\n",
    "mp4 = open('output.mp4', 'rb').read()\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "HTML(f\"\"\"\n",
    "<video width=640 controls>\n",
    "    <source src=\"{data_url}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")\n",
    "\n",
    "# Download the video\n",
    "files.download('output.mp4')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
