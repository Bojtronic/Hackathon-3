{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f66f33",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# üß© 1. Setup\n",
    "# ===============================================================\n",
    "\n",
    "!pip install mediapipe opencv-python tensorflow matplotlib tqdm\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99dd0f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# üß† 2. Model Definition (src/model.py)\n",
    "# ===============================================================\n",
    "\n",
    "def build_model(num_features=2, output_dim=1):\n",
    "    \"\"\"\n",
    "    Simple feed-forward model for posture risk estimation based on angles.\n",
    "    Each input sample is a single frame (no sequence).\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(num_features,)),\n",
    "        tf.keras.layers.Dense(32, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(output_dim, activation='sigmoid')  # 0‚Äì1 risk probability\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65346735",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# üß™ 3. Mock Training (src/mock_training.py)\n",
    "# ===============================================================\n",
    "\n",
    "def train_basic_model(X, y, num_features=2, save_path=\"models/model.h5\"):\n",
    "    \"\"\"\n",
    "    Train a simple posture risk model using angle-based features.\n",
    "    \"\"\"\n",
    "    model = build_model(num_features=num_features)\n",
    "    X = X.reshape((X.shape[0], num_features))\n",
    "\n",
    "    model.fit(\n",
    "        X, y,\n",
    "        validation_split=0.2,\n",
    "        epochs=15,\n",
    "        batch_size=16,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    model.save(save_path)\n",
    "    print(f\"‚úÖ Model saved at {save_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# --- Simulate training data\n",
    "N_SAMPLES = 500\n",
    "N_FEATURES = 2  # e.g., shoulder_angle, neck_angle\n",
    "\n",
    "# Generate synthetic angles (0‚Äì180¬∞)\n",
    "X = np.random.uniform(0, 180, size=(N_SAMPLES, N_FEATURES))\n",
    "\n",
    "# Synthetic labels: risky if average angle > 90¬∞\n",
    "y = (np.mean(X, axis=1) > 90).astype(int)\n",
    "\n",
    "# Train and save model\n",
    "model = train_basic_model(X, y, num_features=N_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925341e0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# ‚öôÔ∏è 4. Risk Assessment (src/risk_assessment.py)\n",
    "# ===============================================================\n",
    "\n",
    "MODEL_PATH = \"models/model.h5\"\n",
    "\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"‚ùå Model not found at {MODEL_PATH}. Run mock training first.\")\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "def assess_posture_risk(angles: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Assess risk based on learned features.\n",
    "    Returns a dictionary with score (0‚Äì100), qualitative risk, and feedback.\n",
    "    \"\"\"\n",
    "    if not angles:\n",
    "        return {\n",
    "            \"score\": 0,\n",
    "            \"risk_level\": \"Unknown\",\n",
    "            \"feedback\": [\"No posture data available.\"]\n",
    "        }\n",
    "\n",
    "    # Convert input angles to a feature vector\n",
    "    feature_vector = np.array(list(angles.values())).reshape(1, -1)\n",
    "    feature_vector = feature_vector / 180.0  # normalize 0‚Äì1\n",
    "\n",
    "    # Predict risk probability\n",
    "    risk_prob = float(model.predict(feature_vector, verbose=0)[0][0])\n",
    "\n",
    "    # Convert probability to score (0‚Äì100)\n",
    "    posture_score = 100 * (1 - risk_prob)\n",
    "    risk_level = (\n",
    "        \"Low\" if posture_score > 85 else\n",
    "        \"Medium\" if posture_score > 60 else\n",
    "        \"High\"\n",
    "    )\n",
    "\n",
    "    feedback = []\n",
    "    if risk_level == \"High\":\n",
    "        feedback.append(\"High-risk posture detected ‚Äî likely instability or strain risk.\")\n",
    "    elif risk_level == \"Medium\":\n",
    "        feedback.append(\"Posture slightly off ideal form, minor adjustment suggested.\")\n",
    "    else:\n",
    "        feedback.append(\"Good posture detected ‚Äî maintain form.\")\n",
    "\n",
    "    return {\n",
    "        \"score\": float(np.clip(posture_score, 0, 100)),\n",
    "        \"risk_level\": risk_level,\n",
    "        \"feedback\": feedback\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767f4269",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# ü¶µ 5. Pose Detection (src/pose_detection.py)\n",
    "# ===============================================================\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"Utility function to calculate the angle between three points.\"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n",
    "    return np.degrees(np.arccos(np.clip(cosine_angle, -1.0, 1.0)))\n",
    "\n",
    "\n",
    "class PoseDetector:\n",
    "    \"\"\"Extracts human keypoints and calculates relevant posture angles.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pose = mp_pose.Pose(\n",
    "            static_image_mode=False,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "\n",
    "    def detect(self, frame):\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = self.pose.process(rgb)\n",
    "\n",
    "        if not results.pose_landmarks:\n",
    "            return {}, {}\n",
    "\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        left_shoulder = (int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].x * w),\n",
    "                         int(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER].y * h))\n",
    "        right_shoulder = (int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].x * w),\n",
    "                          int(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER].y * h))\n",
    "        left_ear = (int(landmarks[mp_pose.PoseLandmark.LEFT_EAR].x * w),\n",
    "                    int(landmarks[mp_pose.PoseLandmark.LEFT_EAR].y * h))\n",
    "\n",
    "        # Calculate posture angles\n",
    "        shoulder_angle = calculate_angle(left_shoulder, right_shoulder, (right_shoulder[0], 0))\n",
    "        neck_angle = calculate_angle(left_ear, left_shoulder, (left_shoulder[0], 0))\n",
    "\n",
    "        angles = {\"shoulder_angle\": shoulder_angle, \"neck_angle\": neck_angle}\n",
    "        keypoints = {\n",
    "            \"left_shoulder\": left_shoulder,\n",
    "            \"right_shoulder\": right_shoulder,\n",
    "            \"left_ear\": left_ear\n",
    "        }\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        return keypoints, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe682b0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# üé® 6. Visualization Helper (src/visualization.py)\n",
    "# ===============================================================\n",
    "\n",
    "def draw_feedback(frame, angles, risk_info):\n",
    "    \"\"\"\n",
    "    Overlay posture angles and risk feedback on the frame.\n",
    "    \"\"\"\n",
    "    color = (0, 255, 0) if risk_info[\"risk_level\"] == \"Low\" else \\\n",
    "            (0, 255, 255) if risk_info[\"risk_level\"] == \"Medium\" else \\\n",
    "            (0, 0, 255)\n",
    "\n",
    "    cv2.putText(frame, f\"Risk: {risk_info['risk_level']}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    cv2.putText(frame, f\"Score: {risk_info['score']:.1f}\", (10, 60),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1)\n",
    "\n",
    "    y = 100\n",
    "    for line in risk_info[\"feedback\"]:\n",
    "        cv2.putText(frame, line, (10, y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1)\n",
    "        y += 25\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175b0ba",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# üé• 7. Upload and Test on a Video\n",
    "# ===============================================================\n",
    "\n",
    "uploaded = files.upload()\n",
    "video_path = list(uploaded.keys())[0]\n",
    "\n",
    "detector = PoseDetector()\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "out_path = \"processed_output.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"‚ùå Failed to read video\")\n",
    "else:\n",
    "    h, w = frame.shape[:2]\n",
    "    out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    for _ in tqdm(range(frames)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        _, angles = detector.detect(frame)\n",
    "        if angles:\n",
    "            risk = assess_posture_risk(angles)\n",
    "            frame = draw_feedback(frame, angles, risk)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"‚úÖ Processed video saved: {out_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6772480",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# ‚ñ∂Ô∏è 8. Display a Few Frames Inline\n",
    "# ===============================================================\n",
    "\n",
    "cap = cv2.VideoCapture(\"processed_output.mp4\")\n",
    "for i in range(50):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
